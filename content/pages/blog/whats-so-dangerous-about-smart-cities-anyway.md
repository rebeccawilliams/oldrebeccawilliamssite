---
title: whats-so-dangerous-about-smart-cities-anyway
date: '2021-05-13'
categories: []
tags: []
excerpt: lorem-ipsum
thumb_image_alt: lorem-ipsum
image_alt: lorem-ipsum
image_position: top
seo:
  title: ''
  description: ''
  robots: []
  extra: []
  type: stackbit_page_meta
layout: post
---
The Belfer Center, home of the Technology and Public Purpose (TAPP) project, was originally created to analyze dangers posed by nuclear
technology. When people ask about my TAPP fellowship, I usually say that I am doing the same analysis, but for “smart cities.” Even for folks
not particularly concerned or interested in “smart cities” this usually sounds spicy enough to pique their interest or at least succinctly
explain what I am up to. In this blog post, I’ll provide an update on what “smart city” technology I am considering and some of the potential harms its misuse introduces.

### What “Smart City” Technology?

The goal of my research is not to examine any one “smart city” technology (which is [an expanding and nebulous list](https://en.wikipedia.org/wiki/Smart_city#Technologies)), but rather the tension between increased state data collection to improve civic services and the risks that collection creates. (In this
way smart city technology is representative of many public data governance issues to come). The “smart city” themed projects that
inspired this research ([LinkNYC](https://www.ny1.com/nyc/all-boroughs/politics/2019/05/09/linknyc-kiosks-surveillance-questions-about-cameras-recording-kiosks-also-losing-money), [Los Angeles’ Mobility Data Specification](https://www.theverge.com/2020/6/8/21284490/aclu-ladot-mds-lawsuit-scooter-tracking-uber), [San Diego Smart ](https://www.vice.com/en/article/z3vn83/streetlight-spy-cameras-have-led-to-a-massive-privacy-backlash-in-san-diego)[Streetlights](https://www.vice.com/en/article/z3vn83/streetlight-spy-cameras-have-led-to-a-massive-privacy-backlash-in-san-diego), and [Sidewalk Toronto](https://privacyinternational.org/examples-abuse/1933/city-toronto-deal-sidewalk-labs-sparks-public-protests)) all involved different technologies and civic aims but aroused similar public concerns regarding unprecedented data collection and how that
data would be used. While each project surely had nuanced trade-offs, what level of care was not being taken by local governments (and their partner vendors) across these projects to provoke public outcry?

The examination of harms that “smart city” technology might contribute to cannot be examined in a vacuum. The issues raised by these
projects are certainly related to the broader Big Tech and privacy regulation debate, but are distinguished from them in that one cannot
individually consent or opt-out of their neighborhood. Further, “smart city” technology is increasingly implicated in growing state
surveillance capabilities (in the U.S. and abroad), but related policy discussions can miss their role if they focus exclusively on [technologies managed by law enforcement agencies](https://www.eff.org/issues/street-level-surveillance) or only consider current uses in the United States.

Rather than focusing on a specific technology, how do these technologies, in context with everything else that is happening in the
world, potentially contribute to harm? How are “smart city” projects [considering harms of further surveilling public spaces](https://some-thoughts.org/robinson.html)? Are relevant “smart city” projects in current [surveillance policy](https://digitalcommons.law.scu.edu/chtlj/vol36/iss5/2/) discussions? What constituencies are prioritized when deciding if the collective utility of new “smart city” data collection is worth the risks? How can the U.S. Federal Government and U.S. based vendors be responsible global actors given these variable environments?

### Potential Harms of Smart City Technology

While some parties will dismiss potential harms of “smart city” technology as alarmist or premature, I see these repeated instances of
public pushback as intrinsically legitimate. The widespread implementation of new technologies that ultimately collect personal data throughout public spaces is uncharted territory. I was recently reminded by a colleague that nuclear risks advocates were similarly
considered to be extremists before Chernobyl, but were ultimately correct in being fearful of a worst-case scenario. Moreover, thoughtful regulation and management of these technologies must be applied to protect against the potential harms (outlined below), and we must forward plan for the worst-case scenarios of mis-using/mismanagement “smart city” technology in order to safeguard our democracy.

In the spirit of these common public concerns, I have started to outline broad categories of harms that might arise from deploying “smart city” technology. The intent of this framework is for it to evolve into an assessment tool for current practices and guide for future considerations of deploying  “smart city“ technology.

#### 1. Lack of Community Input

A first-order issue is does the community where “smart city” technology will be deployed want it? To know the answer to this question means ongoing engagement with a community and robust dialogue about types of data collection, how that might contribute to the collective
good, and all the trade-offs involved. Given the other possible harms involved (see below), projects should not be pursued at all unless the community is on board for an articulated outcome. Challenges for community input on “smart city” technology include ensuring that
approval is informed (perhaps via trusted experts and intermediaries) and identifying the appropriate level of approval (e.g. neighborhood v.
city, majority v. unanimous). Examples like [Sidewalk Lab’s poor public reception (procedurally as well as substantively) to their ](https://ir.lawnet.fordham.edu/cgi/viewcontent.cgi?article=5628\&context=flr)[Master Innovation and Development Plan](https://ir.lawnet.fordham.edu/cgi/viewcontent.cgi?article=5628\&context=flr) highlight the need for this dialogue to take place before the procurement process takes place. Cities like Boston and Seattle have attempted to systematize community input on “smart city” tech with a [Boston Smart City Playbook](https://monum.github.io/playbook/) (which highlights the need for right-tech versus high-tech approaches to civic problem solving) and [Surveillance Impact Report](https://www.seattle.gov/tech/initiatives/privacy/surveillance-technologies/about-surveillance-) processes (which highlights the need for public comment, working group, and council approval of new surveillance technologies).

#### 2. Erosion of Privacy and 4th Amendment Protections

While community input is a first-order issue to deploying “smart city” technology, the rest of these harms are not delineated in any
sequential or ranked order. As technology development moves faster than law, there is a trend of technology expanding possible searches by law
enforcement, and that expansion being challenged in court as a violation of our Fourth Amendment protection from unreasonable searches and seizures. While an individual’s actions or movements in public spaces have historically fallen outside the scope of Fourth Amendment protections, recent case law has inspired some legal scholars, such as Andrew Ferguson, to examine how digital may be considered differently.
In [“Structural Sensor Surveillance” 106 Iowa L. Rev. 47 (2020)](https://ilr.law.uiowa.edu/print/volume-106/structural-sensor-surveillance/) Ferguson considers how automated, continuous, aggregated, long-term
acquisition of personal data with “smart city” sensors may trigger Fourth Amendment scrutiny under current Supreme Court doctrine. Separate from Fourth Amendment protections, as a matter of public policy, one may consider other harms that may occur from an erosion of privacy
including social detriment and a loss of liberty. How are “smart city” technology contracts construing their [privacy policies](https://www.eff.org/deeplinks/2017/09/linknyc-improves-privacy-policy-yet-problems-remain)? Lastly, as “smart city” technology collects more and more data that can be used to re-identify people, the cybersecurity of any information
collected becomes an integral aspect of overall privacy protections. A data breach could lead to re-identifying someone and causing threats to
their safety and wellbeing or economic loss.

#### 3. Chilling of 1st Amendment Rights

In the U.S. the first amendment protects the five freedoms of speech, religion, press, assembly, and the right to petition (protest)
the government. The surveillance imposed by “smart city” could have a chilling effect on community members feeling comfortable participating
in these protected activities for fear of harassment or retaliation by the state. As more instances of filming protestors are documented (such
as in [San Diego streetlight cameras](https://www.voiceofsandiego.org/topics/government/police-used-smart-streetlight-footage-to-investigate-protesters/), [Miami University](https://www.voiceofsandiego.org/topics/government/police-used-smart-streetlight-footage-to-investigate-protesters/), [Hong Kong](https://www.nytimes.com/2019/07/26/technology/hong-kong-protests-facial-recognition-surveillance.html)) one could reasonably anticipate to be filmed and identified in public space. If [public space becomes a place where one fears punishment](https://www-jstor-org.ezp-prod1.hul.harvard.edu/stable/pdf/41426920.pdf?refreqid=excelsior%3A9bf6bcf37caa21d52b3c663494968f17), how will that affect collective action and political movements?

#### 4. Discrimination / Oppression

Because “smart city” tech is applied to a given neighborhood, it shares the potential for discrimination rife in urban planning and
public safety history and also a new power of extending those inequities to the digital worlds term that many have coined as “[digital redlining](https://en.wikipedia.org/wiki/Digital_redlining)”.
Potential harms that flow from disproportionate use or disparate community impact include loss of opportunity, economic loss, and social
determinants (dignitary harms, constraints of bias). Cities, such as [Baltimore and DC](https://cnsmaryland.org/2020/11/19/police-cameras-disproportionately-surveil-nonwhite-areas-of-dc-and-baltimore-cns-finds/), have closed-circuit television (CCTV) installed in in majority nonwhite areas, on average than in majority-white neighborhoods. Detroit has come under scrutiny by local activists for using facial recognition
technology in [public housing](https://www.nytimes.com/2019/09/24/us/politics/facial-recognition-technology-housing.html), spurring [the introduction of Federal legislation](https://www.congress.gov/bill/116th-congress/house-bill/4008/text?r=11\&s=1) to prohibit “the use of biometric recognition technology in certain
federally assisted dwelling units.” These biases compound as data collection from strategically placed “smart city” and other surveillance technology increasingly inform policy decisions such as predictive policing. Seattle’s surveillance law requires [Equity Impact Assessment reporting](https://www.seattle.gov/tech/initiatives/privacy/surveillance-technologies/additional-surveillance-reports) as part of their surveillance technology review process, but to date, the city has articulated an inexpertise in measuring this impact other than examining how it comes up in the public comment.

#### 5. Loss of Accountable Government

Lastly, as governments continue to outsource technology services to private vendors the vendors at play [take on a quasi-government function](https://www.resite.org/stories/bianca-wylie-on-the-critical-design-process-of-democracy-in-smart-cities) without many of the accountability measures built into government functions such as public records access, public auditors, or consequences for elected officials if services do not meet community members expectations. Moreover, if care is not taken with data
governance, community members may be further vulnerable to corporate influence via “surveillance capitalism.” As a“smart city” must be
considered as a potential extension of police surveillance and its biases, it must also be considered as a potential extension of corporate
surveillance. At what point does a single corporation have “vertical integration” (in terms of personal data) of a whole neighborhood? This
corporate influence (via data, and sheer size of these vendors) was central to [Sidewalk Toronto criticism](https://ir.lawnet.fordham.edu/cgi/viewcontent.cgi?article=5628\&context=flr), [Amazon HQ2 criticism](https://www.forbes.com/sites/victoriapavlova/2018/11/08/in-amazons-competition-for-hq2-was-data-the-ultimate-goal/?sh=12e3d37bd039), and [Port Covington criticism](http://data.baltimoresun.com/news/port-covington/). For the data aspect, some cities have retained data rights in their contacts (e.g. [GovEx’s Data Ownership and Usage Terms](https://labs.centerforgov.org/data-governance/data-ownership/)) or “open standards” ([Mobility Data Specification](https://www.openmobilityfoundation.org/about-mds/)) for access to data collected by the private sector but this [raises new questions](https://triangulator.org/blog/local-power-digital-policing/)
of what data the vendor be collecting and managing and what data should governments be collecting and managing. Namely, does this collection
protect individuals, and is the collection [fit for its purpose](https://journals.sagepub.com/doi/10.1177/016555159502100204)? Ultimately data collected for the purposes of consumer payment is more
granular than what is needed for collective city planning and very different from data collected for the purposes of law enforcement. In
addition to these fitness for purpose considerations, [many alternatives](https://foundation.mozilla.org/en/initiatives/data-futures/data-for-empowerment/#10-data-governance-approaches-explored) to data governance have emerged as potential approaches to navigating data spaces that must consider [individual and collective purposes](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3727562), as well as competing individual, corporate, and public interests. How
is data access explicitly or implicitly included in “smart city” vendor business models or contracts? (i.e. Is part of the bargain that the
vendor retains data as a good in exchange for the hardware they provide?) Where no or less money is exchanged, how is data access
considered in public-private partnerships and other test bed scenarios?

### Research Next Steps

The final output goals of this Whose Streets? Our Streets! (Tech Edition) the research project is to provide some high-level recommendations for
governments, the public, and vendors to prevent these harms. The immediate next steps for this project include further refining this set
of harms and collecting examples of current “smart city” tech use and policy. Questions for readers:

*   Do these harm categories resonate?

*   What’s missing?

*   What current or imagined prevention tactics, including [avoiding or postponing ](https://www.aclum.org/en/campaigns/press-pause-face-surveillance)the use[ of certain technologies outright](https://www.aclum.org/en/campaigns/press-pause-face-surveillance), should be considered?

Please send feedback to <rebeccawilliams@hks.harvard.edu> by January 31, 2021.

[*Originally posted on The Perspectives on Public Purpose Blog hosted by Harvard Kennedy School Belfer Center’s Technology and Public Purpose Project (TAPP)*](https://www.belfercenter.org/publication/whats-so-dangerous-about-smart-cities-anyway)
